{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tillämpningar och ML-koncept\n",
    "\n",
    "Grattis! Du har nu byggt ett fullt fungerande Neuralt Nätverk från grunden. Det coola är att matematiken inte bryr sig om vad siffrorna representerar. Pixlar? Pengar? Temperatur? Allt är bara listor med tal.\n",
    "\n",
    "I denna notebook ska vi:\n",
    "1. Använda vårt nätverk för att lösa riktiga problem\n",
    "2. Lära oss om de två stora familjerna av maskininlärning\n",
    "3. Utforska olika typer av data och problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from neural_network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Övning 10: \"Hello World\" för Neurala Nätverk (Siffror)\n",
    "\n",
    "**Syfte:** Att använda vår `NeuralNetwork`-klass för att lösa ett klassiskt problem: Läsa handskrivna siffror."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Träningsdata: 1437 bilder\n",
      "Testdata: 360 bilder\n",
      "Input-storlek: 64 pixlar\n",
      "Output-storlek: 10 klasser (siffrorna 0-9)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 1. Ladda data\n",
    "digits = pd.read_csv('data/digits.csv')\n",
    "\n",
    "data = digits.drop(columns=['target']).values\n",
    "targets = digits['target'].values\n",
    "\n",
    "# 2. Normalisera (0-16 -> 0.0-1.0)\n",
    "X = scaler.fit_transform(data)\n",
    "\n",
    "# 3. One-Hot Encoding\n",
    "y_onehot = []\n",
    "for label in targets:\n",
    "    vector = [0.0] * 10\n",
    "    vector[label] = 1.0\n",
    "    y_onehot.append(vector)\n",
    "\n",
    "# 4. Dela upp i train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Träningsdata: {len(X_train)} bilder\")\n",
    "print(f\"Testdata: {len(X_test)} bilder\")\n",
    "print(f\"Input-storlek: {X.shape[1]} pixlar\")\n",
    "print(f\"Output-storlek: 10 klasser (siffrorna 0-9)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisera några exempel\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i].reshape(8, 8), cmap='gray')\n",
    "    ax.set_title(f\"Siffra: {np.argmax(y_train[i])}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tränar nätverket på handskrivna siffror...\n"
     ]
    }
   ],
   "source": [
    "# 5. Träna nätverket\n",
    "# Input: 64 (pixlar), Hidden: 16, Output: 10 (siffror)\n",
    "nn = NeuralNetwork([64, 16, 10])\n",
    "\n",
    "print(\"Tränar nätverket på handskrivna siffror...\")\n",
    "# TODO: Träna nätverket på ditt X_train och y_train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_test)):\n\u001b[32m      4\u001b[39m     prediction = nn.predict(X_test[i].tolist())\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     guessed_digit = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     actual_digit = np.argmax(y_test[i])\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m guessed_digit == actual_digit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/numpy/_core/fromnumeric.py:1314\u001b[39m, in \u001b[36margmax\u001b[39m\u001b[34m(a, axis, out, keepdims)\u001b[39m\n\u001b[32m   1223\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1224\u001b[39m \u001b[33;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[32m   1225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1311\u001b[39m \u001b[33;03m(2, 1, 4)\u001b[39;00m\n\u001b[32m   1312\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1313\u001b[39m kwds = {\u001b[33m'\u001b[39m\u001b[33mkeepdims\u001b[39m\u001b[33m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np._NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43margmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/numpy/_core/fromnumeric.py:51\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     49\u001b[39m bound = \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(*args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/numpy/_core/fromnumeric.py:43\u001b[39m, in \u001b[36m_wrapit\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# As this already tried the method, subok is maybe quite reasonable here\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# but this follows what was done before. TODO: revisit this.\u001b[39;00m\n\u001b[32m     42\u001b[39m arr, = conv.as_arrays(subok=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m result = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m conv.wrap(result, to_scalar=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "# 6. Utvärdera på testdata\n",
    "correct = 0\n",
    "for i in range(len(X_test)):\n",
    "    prediction = nn.predict(X_test[i].tolist())\n",
    "    guessed_digit = np.argmax(prediction)\n",
    "    actual_digit = np.argmax(y_test[i])\n",
    "    \n",
    "    if guessed_digit == actual_digit:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"\\nNoggrannhet på testdata: {(correct / len(X_test)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa några prediktioner\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    prediction = nn.predict(X_test[i].tolist())\n",
    "    guessed = np.argmax(prediction)\n",
    "    actual = np.argmax(y_test[i])\n",
    "    \n",
    "    ax.imshow(X_test[i].reshape(8, 8), cmap='gray')\n",
    "    color = 'green' if guessed == actual else 'red'\n",
    "    ax.set_title(f\"Gissning: {guessed} (Facit: {actual})\", color=color)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Övning 11: Nya problem, samma kod\n",
    "\n",
    "Hittills har vi gjort **Klassificering** (Svart/Vitt, Katt/Hund, Siffra 0-9). Men kan vi använda samma kod för att **förutsäga framtiden**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario A: Regression (Förutsäga Huspriser)\n",
    "\n",
    "Att gissa ett flyttal (t.ex. temperatur eller pris) kallas **Regression**.\n",
    "\n",
    "Vi har dock ett problem: Vår `Neuron`-klass använder en sigmoid-funktion som alltid ger output mellan 0 och 1. Om vi vill gissa huspriser i hundratusentals dollar, kommer neuronen slå i taket vid 1.0.\n",
    "\n",
    "**Tricket:** Vi måste **normalisera facit**!\n",
    "1. Om dyraste huset kostar 500 000 dollar, låtsas vi att det kostar 1.0\n",
    "2. Vi tränar nätverket\n",
    "3. När nätverket gissar `0.5`, multiplicerar vi med 500 000 för att få det riktiga priset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ladda data (20,000 hus, 8 features per hus)\n",
    "\n",
    "housing = pd.read_csv('data/california_housing.csv')\n",
    "\n",
    "\n",
    "X_house = housing.drop(columns=['median_house_value']).values\n",
    "\n",
    "# Stoppa varje output i en 1-dimensionell lista för att fungera med vårt nätverk\n",
    "y_house = np.array([[cost] for cost in housing['median_house_value']])\n",
    "\n",
    "print(f\"Exempel data: {X_house[0].tolist()}\")\n",
    "print(f\"Exempel pris: ${y_house[0][0]:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. NORMALISERA ALLT\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_house_scaled = scaler_x.fit_transform(X_house)\n",
    "y_house_scaled = scaler_y.fit_transform(y_house)\n",
    "\n",
    "# Dela upp i train/test (använd bara en del av datan för snabbhet)\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(\n",
    "    X_house_scaled[:2000], y_house_scaled[:2000], test_size=0.2\n",
    ")\n",
    "\n",
    "print(f\"Träningsdata: {len(X_train_h)} hus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Träna nätverket\n",
    "# 8 inputs (rum, ålder, läge, etc...), 10 dolda neuroner, 1 output (pris)\n",
    "regressor = NeuralNetwork([8, 10, 1])\n",
    "\n",
    "print(\"Tränar bostadsmäklaren...\")\n",
    "# TODO: Träna nätverket på ditt X_train_h och y_train_h data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Testa och översätt tillbaka!\n",
    "print(\"\\n--- Testar på okända hus ---\")\n",
    "for i in range(5):\n",
    "    pred_scaled = regressor.predict(X_test_h[i].tolist())\n",
    "\n",
    "    # Översätt tillbaka till riktiga pengar\n",
    "    price_guess = scaler_y.inverse_transform(np.array([pred_scaled])).item()\n",
    "    price_real = scaler_y.inverse_transform(np.array([y_test_h[i]])).item()\n",
    "    \n",
    "    print(f\"Gissning: ${price_guess:.0f}, Riktigt pris: ${price_real:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario B: Vin (Multi-class)\n",
    "\n",
    "Låt oss återvända till klassificering men göra det lite svårare. Datasetet **Wine** innehåller kemisk analys av tre olika vinsorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ladda data\n",
    "wine =  pd.read_csv('data/wine.csv')\n",
    "\n",
    "X_wine = wine.drop(columns=['target']).values\n",
    "y_wine = wine['target'].values\n",
    "\n",
    "# 2. Normalisera Inputs\n",
    "scaler = MinMaxScaler()\n",
    "X_wine = scaler.fit_transform(X_wine)\n",
    "\n",
    "# 3. One-Hot Encode Targets\n",
    "y_wine_onehot = pd.get_dummies(y_wine, dtype=int).values.tolist()\n",
    "\n",
    "# TODO: Dela upp i train/test med 30% testdata med sklearns train_test_split\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = [] # TODO\n",
    "\n",
    "print(f\"Features: {X_wine.shape[1]} (alkoholhalt, syra, färg, etc)\")\n",
    "print(f\"Klasser: 3 vinsorter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Träna Sommelieren\n",
    "sommelier = NeuralNetwork([13, 8, 3])\n",
    "\n",
    "print(\"Tränar Sommelieren...\")\n",
    "# TODO: Träna nätverket på ditt X_train_w och y_train_w data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Utvärdera\n",
    "correct = 0\n",
    "for i in range(len(X_test_w)):\n",
    "    probs = sommelier.predict(X_test_w[i].tolist())\n",
    "    guess = np.argmax(probs)\n",
    "    actual = np.argmax(y_test_w[i])\n",
    "    \n",
    "    if guess == actual:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Sommelieren hade rätt på {correct} av {len(X_test_w)} viner.\")\n",
    "print(f\"Accuracy: {(correct / len(X_test_w)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Övning 12: Kan ditt nätverk läsa?\n",
    "\n",
    "För att mata in text i vårt nätverk använder vi en klassisk teknik som heter **Bag of Words**. Tänk dig att vi tar en mening, klipper ut alla ord, och lägger dem i en påse. Vi bryr oss inte om _ordningen_, bara _vilka_ ord som finns med."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Vårt lilla dataset\n",
    "sentences = [\n",
    "    \"jag älskar detta\",\n",
    "    \"detta är fantastiskt\",\n",
    "    \"vilken underbar dag\",\n",
    "    \"maten var god\",\n",
    "    \"jag hatar detta\",\n",
    "    \"detta är hemskt\",\n",
    "    \"vilken hemsk dag\",\n",
    "    \"maten var äcklig\"\n",
    "]\n",
    "\n",
    "# Facit: 1 = Positivt, 0 = Negativt\n",
    "targets = [\n",
    "    [1], [1], [1], [1],  # De 4 första är positiva\n",
    "    [0], [0], [0], [0]   # De 4 sista är negativa\n",
    "]\n",
    "\n",
    "# 2. Bygg Ordboken (Vocabulary)\n",
    "vocabulary = []\n",
    "for s in sentences:\n",
    "    for word in s.split():\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)\n",
    "            \n",
    "print(f\"Nätverket kan {len(vocabulary)} ord: {vocabulary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Hjälpfunktion: Text till Siffror\n",
    "def text_to_vector(text):\n",
    "    vector = [0] * len(vocabulary)\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            index = vocabulary.index(word)\n",
    "            vector[index] = 1\n",
    "    return vector\n",
    "\n",
    "# Testa funktionen\n",
    "print(f\"Test: 'jag hatar' -> {text_to_vector('jag hatar')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Förbered träningsdatan\n",
    "X_text = [text_to_vector(s) for s in sentences]\n",
    "y_text = targets\n",
    "\n",
    "# 5. Träna Nätverket\n",
    "text_nn = NeuralNetwork([len(vocabulary), 4, 1])\n",
    "\n",
    "print(\"Lär nätverket svenska...\")\n",
    "# TODO: Träna nätverket på ditt X_text och y_text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Testa på NYA meningar\n",
    "print(\"\\n--- Testar nätverkets språkkänsla ---\")\n",
    "\n",
    "test_sentences = [\n",
    "    \"jag älskar maten\",      # En mix av ord den sett i positiva sammanhang\n",
    "    \"detta är äckligt\",      # En mix av ord den sett i negativa sammanhang\n",
    "    \"jag hatar maten\",       # Ny kombination\n",
    "    \"fantastiskt underbar\",  # Två positiva ord\n",
    "]\n",
    "\n",
    "for s in test_sentences:\n",
    "    vec = text_to_vector(s)\n",
    "    prediction = text_nn.predict(vec)[0]\n",
    "    \n",
    "    sentiment = \"POSITIV :)\" if prediction > 0.5 else \"NEGATIV :(\"\n",
    "    print(f\"Mening: '{s}' -> Gissning: {prediction:.2f} -> {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analys: Vad hände precis?\n",
    "\n",
    "Om du kör koden kommer du se att nätverket troligen gissar rätt på \"jag älskar maten\", trots att den meningen **aldrig fanns i träningsdatan**!\n",
    "\n",
    "Hur?\n",
    "1. Nätverket lärde sig att ordet \"älskar\" har en stark koppling till positiv output (1)\n",
    "2. Det lärde sig att \"maten\" är neutralt (finns i både bra och dåliga meningar)\n",
    "3. När du kombinerar dem väger \"älskar\" tyngre, och summan blir positiv\n",
    "\n",
    "Du har precis byggt en AI som förstår (vissa) ords innebörd baserat på erfarenhet!\n",
    "\n",
    "### Begränsningen (Varför detta inte är ChatGPT)\n",
    "\n",
    "Ditt nätverk använder \"Bag of Words\". Det betyder att den tappar bort **ordföljden**. För ditt nätverk betyder följande två meningar exakt samma sak:\n",
    "\n",
    "1. *\"Mat var inte bra, den var dålig\"*\n",
    "2. *\"Mat var inte dålig, den var bra\"*\n",
    "\n",
    "För att förstå skillnaden behöver man nätverk som har **minne** och läser ord i sekvens (som Transformers/GPT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Övning 13: Spionkameran (Autoencoder & Denoising)\n",
    "\n",
    "Hittills har vi matat in en bild och fått ut en etikett. Men vad händer om **input är en bild** och **output också är en bild**?\n",
    "\n",
    "Detta kallas för en **Autoencoder**. Det används för att:\n",
    "- Restaurera gamla foton\n",
    "- Ta bort brus\n",
    "- Komprimera data\n",
    "\n",
    "**Uppdraget:** Dina spionsatelliter skickar ner bilder på siffror, men atmosfären lägger till massa \"brus\". Vi ska träna nätverket att ta bort bruset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ladda data\n",
    "\n",
    "digits = pd.read_csv('data/digits.csv')\n",
    "data = digits.drop(columns=['target']).values\n",
    "X_clean = scaler.fit_transform(data)\n",
    "\n",
    "# 2. Skapa \"trasig\" data (Lägg till brus)\n",
    "noise_factor = 0.5\n",
    "X_noisy = X_clean + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_clean.shape)\n",
    "X_noisy = np.clip(X_noisy, 0., 1.)  # Klipp till 0-1\n",
    "\n",
    "# Dela upp: X_noisy är INPUT, X_clean är FACIT\n",
    "X_train_noisy, X_test_noisy, X_train_clean, X_test_clean = train_test_split(\n",
    "    X_noisy, X_clean, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Träningsdata: {len(X_train_noisy)} bilder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisera brusiga vs rena bilder\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i in range(5):\n",
    "    axes[0, i].imshow(X_train_noisy[i].reshape(8, 8), cmap='gray')\n",
    "    axes[0, i].set_title('Brusig')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(X_train_clean[i].reshape(8, 8), cmap='gray')\n",
    "    axes[1, i].set_title('Original')\n",
    "    axes[1, i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Bygg Autoencodern\n",
    "# Input: 64 pixlar\n",
    "# Hidden: 32 neuroner (Vi tvingar nätverket att komprimera!)\n",
    "# Output: 64 pixlar\n",
    "autoencoder = NeuralNetwork([64, 32, 64])\n",
    "\n",
    "print(\"Tränar på att ta bort brus...\")\n",
    "# Notera: Vi tränar med NOISY som input och CLEAN som target!\n",
    "autoencoder.train(X_train_noisy[:500].tolist(), X_train_clean[:500].tolist(), epochs=50, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualisera Resultatet\n",
    "idxs = np.random.randint(0, len(X_test_noisy), 5)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, idx in enumerate(idxs):\n",
    "    # A. Den trasiga bilden (Input)\n",
    "    ax = plt.subplot(3, 5, i + 1)\n",
    "    plt.imshow(X_test_noisy[idx].reshape(8, 8), cmap='gray')\n",
    "    ax.axis('off')\n",
    "    if i == 2: ax.set_title('Input (Brusig)')\n",
    "\n",
    "    # B. Nätverkets lagning (Output)\n",
    "    reconstructed = np.array(autoencoder.predict(X_test_noisy[idx].tolist()))\n",
    "    ax = plt.subplot(3, 5, i + 1 + 5)\n",
    "    plt.imshow(reconstructed.reshape(8, 8), cmap='gray')\n",
    "    ax.axis('off')\n",
    "    if i == 2: ax.set_title('Output (Lagad)')\n",
    "\n",
    "    # C. Facit (Originalet)\n",
    "    ax = plt.subplot(3, 5, i + 1 + 10)\n",
    "    plt.imshow(X_test_clean[idx].reshape(8, 8), cmap='gray')\n",
    "    ax.axis('off')\n",
    "    if i == 2: ax.set_title('Original (Facit)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Övning 14: Sinus\n",
    "\n",
    "Det finns en matematisk sats som heter **\"Universal Approximation Theorem\"**. Den säger att ett neuralt nätverk med minst ett dolt lager kan lära sig **vilken matematisk funktion som helst**.\n",
    "\n",
    "Låt oss bevisa det genom att lära nätverket en **Sinuskurva**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Skapa Data: En Sinusvåg\n",
    "X_sin = np.linspace(0, 2 * np.pi, 30).reshape(-1, 1)\n",
    "y_sin = np.sin(X_sin)\n",
    "\n",
    "# 2. Normalisera för Sigmoid\n",
    "# Sinus går från -1 till 1. Vi flyttar det till 0 till 1.\n",
    "y_sin_shifted = (y_sin + 1) / 2\n",
    "X_sin_normalized = X_sin / (2 * np.pi)\n",
    "\n",
    "# Gör om till listor\n",
    "X_sin_list = X_sin_normalized.tolist()\n",
    "y_sin_list = y_sin_shifted.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Bygg Nätverket\n",
    "# 1 Input (x-värdet)\n",
    "# 10 Dolda neuroner\n",
    "# 1 Output (y-värdet)\n",
    "math_network = NeuralNetwork([1, 10, 1])\n",
    "\n",
    "print(\"Lär nätverket att rita vågor...\")\n",
    "math_network.train(X_sin_list, y_sin_list, epochs=2000, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Förutsäg och Rita\n",
    "predictions = []\n",
    "for val in X_sin_normalized:\n",
    "    pred = math_network.predict(val.tolist())\n",
    "    predictions.append(pred[0])\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Plotta\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_sin, y_sin_shifted, label='Facit (Sinus)', color='gray', s=30)\n",
    "plt.plot(X_sin, predictions, label='Nätverkets gissning', color='red', linewidth=3)\n",
    "plt.title('Neuralt Nätverk lär sig Sinus-funktionen')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y (normaliserad)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## De Två Stora Familjerna av ML\n",
    "\n",
    "Klassisk maskininlärning delas oftast in i två huvudkategorier, baserat på vilken typ av data man har och vad man vill uppnå."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning (Övervakad Inlärning)\n",
    "\n",
    "Detta är den vanligaste formen av maskininlärning och den vi har arbetat med hittills. \"Övervakad\" betyder att vi tränar modellen på ett dataset där vi redan känner till de korrekta svaren. Vi har en \"facitlista\".\n",
    "\n",
    "Målet är att modellen ska lära sig den underliggande funktionen som kopplar ihop en input med en korrekt output.\n",
    "\n",
    "**Två huvudtyper:**\n",
    "\n",
    "1. **Klassificering:** Förutsäga en kategorisk etikett\n",
    "   - *Exempel:* Spam-filtrering, bildigenkänning, pingvinarter\n",
    "\n",
    "2. **Regression:** Förutsäga ett kontinuerligt värde\n",
    "   - *Exempel:* Huspriser, försäljningsprognoser, temperatur\n",
    "\n",
    "![Supervised learning](./images/classification.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning (Oövervakad Inlärning)\n",
    "\n",
    "Här har vi den motsatta situationen. Vi har ett dataset, men vi har ingen aning om vad de \"korrekta\" svaren är. Målet är att låta modellen på egen hand hitta dolda mönster och strukturer i datan.\n",
    "\n",
    "**Två vanliga uppgifter:**\n",
    "\n",
    "1. **Clustering (Klustring):** Hitta naturliga grupperingar\n",
    "   - *Exempel:* Kundsegmentering, anomalidetektering\n",
    "\n",
    "2. **Dimensionality Reduction:** Komprimera data smart\n",
    "   - *Exempel:* PCA för att visualisera högdimensionell data\n",
    "\n",
    "![Unsupervised learning](./images/clustering.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA (Principal Component Analysis)\n",
    "\n",
    "Om du tävlar i AI (t.ex. IOAI) kommer du ständigt stöta på data med _för många_ kolumner. Det klassiska verktyget för att hantera detta är **PCA**.\n",
    "\n",
    "Tänk dig ett moln av punkter format som en utdragen baguette i 3D-rymden:\n",
    "\n",
    "1. **PCA hittar \"Huvudriktningen\":** Den drar en linje genom baguettens längd (där datan varierar mest). Detta är \"Principal Component 1\".\n",
    "2. **PCA hittar nästa riktning:** Den drar en ny linje vinkelrätt mot den första, genom baguettens bredd.\n",
    "3. **Platta till:** Genom att bara behålla dessa två linjer och kasta bort höjden (som kanske bara är brus), har vi komprimerat 3D-objektet till en 2D-skiva.\n",
    "\n",
    "**Användningsområden:**\n",
    "- Visualisera komplex data i 2D\n",
    "- Ta bort brus (behåll bara de viktigaste komponenterna)\n",
    "- Skapa nya features som är bättre för din modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Svenska exempel\n",
    "\n",
    "Under 2000-talet, när datorkraften och mängden tillgänglig data exploderade, blev maskininlärning ryggraden i många av de mest framgångsrika tech-bolagen.\n",
    "\n",
    "### Klarna\n",
    "Hela Klarnas affärsmodell bygger på att snabbt kunna fatta ett kreditbeslut. När du klickar på \"Köp nu, betala senare\" måste de på en bråkdels sekund avgöra hur troligt det är att du faktiskt kommer att betala. Detta görs med en **regressionsmodell** som tar hundratals variabler (din köphistorik, tid på dygnet, typ av produkt, etc.) och producerar en \"riskpoäng\".\n",
    "\n",
    "### Spotify\n",
    "Hur kan Spotify upplevas som att den \"känner\" din musiksmak? Deras rekommendationsmotorer kombinerar flera ML-tekniker:\n",
    "\n",
    "- **Kollaborativ filtrering (Unsupervised):** Systemet använder clustering för att hitta andra användare vars musiksmak liknar din. Den tittar sedan på vad de lyssnar på som du inte har upptäckt.\n",
    "- **Content-Based Filtering (Supervised):** Spotify analyserar ljudfilerna direkt för att extrahera hundratals musikaliska egenskaper (tempo, \"dansbarhet\", tonart etc.). Din \"smakprofil\" matchas mot nya låtar med liknande egenskaper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Perspektiv på Klassisk Maskininlärning\n",
    "\n",
    "### Det filosofiska perspektivet: Empirismens Återkomst\n",
    "Maskininlärning representerar en seger för **empirismen**. AI-forskare slutade försöka förprogrammera \"sanningen\". Istället skapade de system som kunde lära sig från erfarenhet (data). En ML-modell är en modern \"Tabula Rasa\", en oskriven tavla som fylls med kunskap genom observation av världen.\n",
    "\n",
    "### Det ekonomiska perspektivet\n",
    "ML skapade ett enormt ekonomiskt värde. Amazons rekommendationsmotor sägs stå för över en tredjedel av deras totala försäljning. ML var inte längre en akademisk leksak; det var en affärskritisk motor.\n",
    "\n",
    "### Det sociologiska perspektivet: Filterbubblor\n",
    "När företag som YouTube och Facebook började använda ML för att personalisera sina flöden, uppstod **filterbubblor**. Algoritmerna har inget ont uppsåt - deras enda mål är att maximera din tid på plattformen. Men genom att optimera för engagemang, gynnar de oavsiktligt innehåll som är chockerande eller extremt.\n",
    "\n",
    "### Det kognitiva perspektivet: Uppmärksamhetsekonomin\n",
    "Sociala medier använder **intermittent förstärkning** - samma princip som gör spelautomater beroendeframkallande. Du vet aldrig _när_ nästa belöning kommer, vilket får dig att fortsätta skrolla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Vad har vi lärt oss?\n",
    "\n",
    "I denna notebook har vi:\n",
    "\n",
    "1. Använt vårt nätverk för att läsa **handskrivna siffror** (94%+ noggrannhet!)\n",
    "2. Löst **regression** (huspriser) och **multi-class klassificering** (vin)\n",
    "3. Byggt en enkel **textanalys** med Bag of Words\n",
    "4. Skapat en **Autoencoder** för att ta bort brus från bilder\n",
    "5. Bevisat **Universal Approximation Theorem** genom att lära en sinuskurva\n",
    "6. Lärt oss skillnaden mellan **Supervised** och **Unsupervised Learning**\n",
    "7. Diskuterat **perspektiv** på ML: filosofiskt, ekonomiskt, sociologiskt\n",
    "\n",
    "## Nästa steg\n",
    "\n",
    "Du har nu byggt grunden. Men för att bygga professionella nätverk behöver du:\n",
    "- Optimerare som **Adam**\n",
    "- Aktiveringsfunktioner som **ReLU**\n",
    "- Tekniker som **Dropout**\n",
    "- Ramverk som **Keras/PyTorch**\n",
    "\n",
    "Men grundprincipen är densamma: vikter, bias, framåtpass, bakåtpass. Det du lärt dig här är fundamentet som alla avancerade tekniker bygger på.\n",
    "\n",
    "**Grattis - du har byggt ett neuralt nätverk från grunden!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
