{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras: Fr√•n dina n√§tverk till professionella verktyg\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DITT-REPO/06_keras.ipynb)\n",
    "\n",
    "Du har byggt neurala n√§tverk fr√•n grunden. Nu ska vi se hur samma sak g√∂rs med Keras - och sedan utforska nya m√∂jligheter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 3.10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Del 1: Bekanta problem i Keras\n",
    "\n",
    "F√∂rst l√∂ser vi samma typ av problem som du redan kan - men med Keras syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Din kod vs Keras\n\n| Din kod | Keras | Vad det g√∂r |\n|---------|-------|-------------|\n| `NeuralNetwork([64, 16, 10])` | `Input(shape=(...)), Dense(16), Dense(10)` | Definiera lager |\n| `sigmoid()` | `activation='sigmoid'` | Aktiveringsfunktion |\n| `sigmoid_derivative()` | *(automatiskt!)* | Keras ber√§knar derivator √•t dig |\n| `learning_rate=0.5` | `optimizer=SGD(learning_rate=0.5)` | Inl√§rningsfaktor |\n| `train()` | `model.fit()` | Tr√§na n√§tverket |\n| `predict()` | `model.predict()` | G√∂r prediktioner |\n\n### Input-lagret: ber√§tta f√∂r Keras hur datan ser ut\n\nVarje modell b√∂rjar med `layers.Input(shape=...)` som talar om **dimensionerna f√∂r ett enda exempel**. `shape` tar en tupel med en siffra per dimension:\n\n```\nEn bil   = en lista med 21 tal               ‚Üí Input(shape=(21,))         1D\nEn bild  = 100 rader √ó 100 kolumner √ó 3 f√§rger  ‚Üí Input(shape=(100, 100, 3))  3D\nEn text  = en sekvens av 40 tecken-index      ‚Üí Input(shape=(40,))         1D\n```\n\nT√§nk p√• det som: *\"Vilka dimensioner har EN datapunkt?\"* ‚Äî inte datan i sig, utan dess form."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √ñvning 1: Bilkvalitet üöó\n",
    "\n",
    "Multi-klass klassificering: Bed√∂m om en bil √§r \"unacceptable\", \"acceptable\", \"good\" eller \"very good\" baserat p√• pris, underh√•ll, d√∂rrar, etc.\n",
    "\n",
    "Dataset: [UCI Car Evaluation](https://archive.ics.uci.edu/ml/datasets/car+evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Ladda Car Evaluation fr√•n UCI\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
    "columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "cars = pd.read_csv(url, names=columns)\n",
    "\n",
    "print(\"Bildata:\")\n",
    "print(cars.head())\n",
    "print(f\"\\nKlasser: {cars['class'].unique()}\")\n",
    "print(f\"Antal exempel: {len(cars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Konvertera kategorier till tal\n# Varje kolumn har ordnade kategorier - vi kodar dem som tal\n\n# Features\nX = pd.get_dummies(cars.drop('class', axis=1)).values\n\n# Target\nclass_encoder = LabelEncoder()\ny = class_encoder.fit_transform(cars['class'])\nclass_names = class_encoder.classes_\n\n# Dela upp\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"Features: {X.shape[1]} (one-hot encoded)\")\nprint(f\"  buying:   4 v√§rden (vhigh, high, med, low)\")\nprint(f\"  maint:    4 v√§rden\")\nprint(f\"  doors:    4 v√§rden (2, 3, 4, 5more)\")\nprint(f\"  persons:  3 v√§rden (2, 4, more)\")\nprint(f\"  lug_boot: 3 v√§rden (small, med, big)\")\nprint(f\"  safety:   3 v√§rden (low, med, high)\")\nprint(f\"  Totalt:   4+4+4+3+3+3 = {X.shape[1]} kolumner\")\nprint(f\"\\nKlasser: {list(class_names)}\")\nprint(f\"Tr√§ningsexempel: {len(X_train)}, Test: {len(X_test)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Bygg modell - j√§mf√∂r med NeuralNetwork([21, 16, 4])\nmodel_cars = keras.Sequential([\n    layers.Input(shape=(21,)),          # En bil = 21 features (one-hot encoded)\n    layers.Dense(16, activation='sigmoid'),\n    layers.Dense(4, activation='sigmoid')  # 4 klasser\n])\n\n# Kompilera\n# mse som loss och sgd som optimizer utan momentum √§r likv√§rdigt\n# med den kod som du sj√§lv tidigare skrivit i Python\nmodel_cars.compile(\n    optimizer=keras.optimizers.SGD(learning_rate=0.5, momentum=0.0),\n    loss='mse', \n    metrics=['accuracy']\n)\n\nmodel_cars.summary()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Tr√§na\nfrom keras.utils import to_categorical\n\n# One-hot encode the labels to be compatible with 'mse' loss and 4 output units\ny_train_one_hot = to_categorical(y_train, num_classes=4)\ny_test_one_hot = to_categorical(y_test, num_classes=4)\n\nhistory = model_cars.fit(\n    X_train, y_train_one_hot,\n    epochs=100,\n    validation_split=0.2,\n    verbose=0\n)\n\n# Utv√§rdera\nloss, acc = model_cars.evaluate(X_test, y_test_one_hot, verbose=0)\nprint(f\"Test Accuracy: {acc*100:.1f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras ger oss tr√§ningshistorik - plotta den!\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Tr√§ning')\n",
    "plt.plot(history.history['val_loss'], label='Validering')\n",
    "plt.title('F√∂rlust (Loss)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Tr√§ning')\n",
    "plt.plot(history.history['val_accuracy'], label='Validering')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Samma koncept som din NeuralNetwork!** Dense-lager, sigmoid, f√∂rlustfunktion, epochs. Bara annan syntax - och vi f√•r fin tr√§ningshistorik p√• k√∂pet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Olika inst√§llningar\n",
    "\n",
    "Hittills har du anv√§nt sigmoidfunktionen som aktiveringsfunktion. Den kl√§mmer ihop v√§rden mellan 0-1.\n",
    "\n",
    "ReLU √§r ett annat alternativ som visat sig fungera v√§ldigt bra. Den s√§tter negativa v√§rden till 0 och beh√•ller positiva v√§rden. Supersimpel! Denna √§r oerh√∂rt vanlig att den anv√§nds f√∂r g√∂mda lager.\n",
    "\n",
    "**ReLU** (Rectified Linear Unit):\n",
    "```\n",
    "ReLU(x) = max(0, x)\n",
    "```\n",
    "- Derivatan √§r 1 f√∂r positiva v√§rden ‚Üí ingen vanishing gradient\n",
    "- Snabbare att ber√§kna\n",
    "\n",
    "**Softmax** \n",
    "\n",
    "Ett alternativ till sigmoid f√∂r sista lagret. Sigmoid kl√§mmer ihop alla enskilda outputs mellan 0 och 1. Softmax kl√§mmer ihop alla outputs s√• att de tillsammans summerar till 1. Likt sigmoid tolkar vi fortfarande det st√∂rsta v√§rdet som den med st√∂rst sannolikhet.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Vi har hittills haft en statisk learning rate f√∂r alla vikter i hela n√§tverket. Det finns b√§ttre strategier f√∂r att hantera hur mycket vikter ska justeras. Vi st√§ller in olika _optimizers_ f√∂r att uppn√• detta.\n",
    "\n",
    "**Adam** optimizer:\n",
    "- Anpassar learning rate automatiskt per vikt\n",
    "- Fungerar ofta b√§ttre √§n SGD\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samma dataset, men nya inst√§llningar\n",
    "\n",
    "Nedan kan du se hur vi tr√§nar p√• samma bil-data men anv√§nder *_relu_*, *_softmax_*, *_adam_* och en annan loss funktion som √§r b√§ttre anpassad f√∂r multi-class classification: *_sparse_categorical_crossentropy_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# J√§mf√∂r sigmoid/SGD vs ReLU/Adam\nmodel_modern = keras.Sequential([\n    layers.Input(shape=(21,)),\n    layers.Dense(16, activation='relu'),\n    layers.Dense(4, activation='softmax')\n])\n\nmodel_modern.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel_modern.fit(X_train, y_train, epochs=100, verbose=0)\n\n_, acc_modern = model_modern.evaluate(X_test, y_test, verbose=0)\nprint(f\"Sigmoid + SGD + MSE:  {acc*100:.1f}%\")\nprint(f\"ReLU + Adam + sparse_categorical_crossentropy:    {acc_modern*100:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üß™ Uppgift 1: Experimentera med arkitekturen\n",
    "\n",
    "Modellen ovan har **ett** dolt lager med 16 neuroner. \n",
    "\n",
    "**Din uppgift:** Skapa en ny modell med **tv√•** dolda lager (t.ex. 32 och 16 neuroner). Tr√§na och j√§mf√∂r accuracy.\n",
    "\n",
    "Tips: Kopiera koden ovan och l√§gg till ett lager mellan input och output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kod h√§r - skapa en modell med tv√• dolda lager\n",
    "model_deeper = keras.Sequential([\n",
    "    # TODO: L√§gg till lager h√§r\n",
    "])\n",
    "\n",
    "# Kompilera och tr√§na\n",
    "# model_deeper.compile(...)\n",
    "# model_deeper.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Del 2: Bilder - Nya lagertyper\n",
    "\n",
    "Dina n√§tverk hade bara `Dense`-lager. F√∂r bilder finns specialiserade lager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemet med Dense f√∂r bilder\n",
    "\n",
    "En 300√ó300 bild har 90 000 pixlar. Med Dense-lager:\n",
    "- Varje neuron kopplas till ALLA 90 000 pixlar\n",
    "- Vi f√∂rlorar information om att pixlar som √§r n√§ra varandra h√∂r ihop\n",
    "- Massor av parametrar\n",
    "\n",
    "**L√∂sning: Convolutional Neural Networks (CNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Conv2D - Convolutional Layer\n\nIst√§llet f√∂r att titta p√• hela bilden samtidigt, anv√§nder vi ett litet \"f√∂nster\" (filter/kernel) som r√∂r sig √∂ver bilden.\n\n### Grundid√©n\n\nEtt filter (kernel) √§r en liten matris med vikter som glider √∂ver bilden. P√• varje position multipliceras filtrets vikter med pixlarna under det, allt summeras, och man l√§gger till ett bias-v√§rde. Resultatet blir **en pixel** i output-bilden.\n\n### Konkret exempel (en kanal)\n\n```\nBild (5√ó5):              Filter (3√ó3):        Bias: 0\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  1   2   3  4  5 ‚îÇ     ‚îÇ  1   0  -1 ‚îÇ\n‚îÇ  0   1   2  3  4 ‚îÇ     ‚îÇ  1   0  -1 ‚îÇ\n‚îÇ  1   0   1  2  3 ‚îÇ     ‚îÇ  1   0  -1 ‚îÇ\n‚îÇ  2   1   0  1  2 ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îÇ  1   1   1  1  1 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**Steg 1:** Placera filtret i √∂vre v√§nstra h√∂rnet (rad 0, kolumn 0):\n\n```\nFiltret ligger √∂ver dessa 9 pixlar:\n\n [1] [2] [3]  4   5       1√ó1 + 2√ó0 + 3√ó(-1)  =  1 + 0 - 3 = -2\n [0] [1] [2]  3   4       0√ó1 + 1√ó0 + 2√ó(-1)  =  0 + 0 - 2 = -2\n [1] [0] [1]  2   3       1√ó1 + 0√ó0 + 1√ó(-1)  =  1 + 0 - 1 =  0\n  2   1   0   1   2                            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n  1   1   1   1   1       Summa + bias = -2 + (-2) + 0 + 0 = -4\n\n                          ‚Üí ReLU(-4) = 0  ‚Üê output-pixel [0,0]\n```\n\n**Steg 2:** Flytta filtret ett steg √•t h√∂ger (rad 0, kolumn 1):\n\n```\n  1  [2] [3] [4]  5       2√ó1 + 3√ó0 + 4√ó(-1)  =  2 + 0 - 4 = -2\n  0  [1] [2] [3]  4       1√ó1 + 2√ó0 + 3√ó(-1)  =  1 + 0 - 3 = -2\n  1  [0] [1] [2]  3       0√ó1 + 1√ó0 + 2√ó(-1)  =  0 + 0 - 2 = -2\n  2   1   0   1   2                            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n  1   1   1   1   1       Summa + bias = -2 + (-2) + (-2) + 0 = -6\n\n                          ‚Üí ReLU(-6) = 0  ‚Üê output-pixel [0,1]\n```\n\n**Steg 3, 4, ...** Forts√§tt tills filtret glidit √∂ver alla positioner. Hela output-bilden:\n\n```\nOutput (3√ó3):\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  0   0   0 ‚îÇ    Varje v√§rde √§r resultatet av (filter √ó pixlar + bias)\n‚îÇ  0   0   0 ‚îÇ    genom ReLU-aktiveringen.\n‚îÇ  0   0   0 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n*(Det h√§r filtret letar efter vertikala kanter ‚Äî skillnaden mellan v√§nster och h√∂ger sida. Bilden saknar starka s√•dana kanter, s√• allt blir 0 efter ReLU.)*\n\n### Varf√∂r krymper bilden?\n\nFiltret m√•ste \"passa in\" helt i bilden. Ett 3√ó3 filter kan inte centreras p√• en pixel i allra yttersta kanten, f√∂r det saknas pixlar utanf√∂r bilden:\n\n```\n5√ó5 bild med 3√ó3 filter:\n\n  ‚ùå Filtret kan inte starta h√§r (inget ovanf√∂r/till v√§nster)\n  ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ . . . . .   ‚îÇ    Filtret kan centreras p√• de inre 3√ó3 positionerna\n‚îÇ . ‚úì ‚úì ‚úì .   ‚îÇ    ‚Üí output blir (5-3+1) √ó (5-3+1) = 3√ó3\n‚îÇ . ‚úì ‚úì ‚úì .   ‚îÇ\n‚îÇ . ‚úì ‚úì ‚úì .   ‚îÇ    Generellt: output = input - filter + 1\n‚îÇ . . . . .   ‚îÇ    Exempel: 100 - 3 + 1 = 98\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\nS√• en 100√ó100 bild blir **98√ó98** efter ett 3√ó3 filter ‚Äî vi \"f√∂rlorar\" 1 pixel p√• varje sida.\n\n### Varje filter har vikter per kanal\n\nEn RGB-bild har **3 kanaler** (r√∂d, gr√∂n, bl√•). Varje filter i Conv2D har en **egen viktmatris per kanal**, plus **ett bias-v√§rde**:\n\n```\nInput: 100√ó100√ó3 (RGB)\n\n                    Filter #1 (en \"neuron\"):\n                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n  R√∂d kanal    ‚Üí    ‚îÇ 3√ó3 vikter ‚îÇ  ‚Üê 9 vikter\n                    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n  Gr√∂n kanal   ‚Üí    ‚îÇ 3√ó3 vikter ‚îÇ  ‚Üê 9 vikter     Totalt: 3√ó3√ó3 + 1 = 28 parametrar\n                    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n  Bl√• kanal    ‚Üí    ‚îÇ 3√ó3 vikter ‚îÇ  ‚Üê 9 vikter\n                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                    + 1 bias\n```\n\nFiltret ber√§knar: **(summa av alla 27 vikter √ó motsvarande pixlar) + bias ‚Üí 1 tal**\n\nMed `Conv2D(32, (3,3))` skapar vi **32 s√•dana filter**, vart och ett med egna vikter:\n- Parametrar per filter: 3 √ó 3 √ó 3 + 1 = **28**\n- Totalt: 28 √ó 32 = **896 parametrar**\n\nVarje filter producerar en **98√ó98 output-bild** (en \"kanal\"). 32 filter ‚Üí output blir **98√ó98√ó32**.\n\n### Hela f√∂rsta blocket steg f√∂r steg\n\n```\nInput:    100 √ó 100 √ó 3   (RGB-bild)\n              ‚îÇ\n         Conv2D(32, 3√ó3)   ‚Üí 98 √ó 98 √ó 32    (krympt 2 px, 32 filterresultat)\n              ‚îÇ                                  896 parametrar\n         MaxPooling(2√ó2)   ‚Üí 49 √ó 49 √ó 32    (halverad storlek)\n              ‚îÇ                                  0 parametrar (bara tar max)\n         Conv2D(64, 3√ó3)   ‚Üí 47 √ó 47 √ó 64    (krympt 2 px, nu 64 filter)\n              ‚îÇ                                  varje filter: 3√ó3√ó32 + 1 = 289 params\n              ‚îÇ                                  totalt: 289 √ó 64 = 18 496 parametrar\n         MaxPooling(2√ó2)   ‚Üí 23 √ó 23 √ó 64\n              ‚îÇ\n              ...\n```\n\nL√§gg m√§rke till andra Conv2D-lagret: inputen har nu **32 kanaler** (fr√•n de 32 filtren i f√∂rra lagret), s√• varje filter beh√∂ver 3√ó3√ó**32** vikter + 1 bias.\n\n**F√∂rdelar med CNN:**\n- L√§r sig lokala m√∂nster (kanter, former)\n- Samma filter anv√§nds √∂verallt ‚Üí f√§rre parametrar\n- Hittar m√∂nster oavsett var i bilden de √§r"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxPooling2D - Krymper bilden\n",
    "\n",
    "Efter convolution vill vi g√∂ra bilden mindre (snabbare, mindre overfitting).\n",
    "\n",
    "```\n",
    "Input (4√ó4):           MaxPool (2√ó2):      Output (2√ó2):\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ 1  3 ‚îÇ 2  1 ‚îÇ        Ta max i           ‚îÇ 3 ‚îÇ 2 ‚îÇ\n",
    "‚îÇ 2  1 ‚îÇ 1  2 ‚îÇ   ‚Üí    varje 2√ó2 ruta  ‚Üí  ‚îÇ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÇ\n",
    "‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                           ‚îÇ 6 ‚îÇ 4 ‚îÇ\n",
    "‚îÇ 5  6 ‚îÇ 3  4 ‚îÇ                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "‚îÇ 1  2 ‚îÇ 1  1 ‚îÇ                            \n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            \n",
    "```\n",
    "\n",
    "**Varf√∂r max?** Vi bryr oss om \"finns det en kant h√§r?\" inte exakt var."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten - Platta ut till 1D\n",
    "\n",
    "Efter CNN-lagren har vi fortfarande en 2D-bild. `Flatten` g√∂r den till en 1D-vektor som kan g√• in i Dense-lager.\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         \n",
    "‚îÇ 1 ‚îÇ 2 ‚îÇ         \n",
    "‚îÇ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÇ   ‚Üí     [1, 2, 3, 4]\n",
    "‚îÇ 3 ‚îÇ 4 ‚îÇ         \n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √ñvning 2: Rock Paper Scissors ‚úä‚úã‚úåÔ∏è\n",
    "\n",
    "Klassificera handgester med ett CNN.\n",
    "\n",
    "Dataset: [TensorFlow Rock Paper Scissors](https://www.tensorflow.org/datasets/catalog/rock_paper_scissors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Ladda Rock Paper Scissors\n",
    "(train_ds, test_ds), info = tfds.load(\n",
    "    'rock_paper_scissors',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "class_names = ['rock', 'paper', 'scissors']\n",
    "print(f\"Tr√§ningsbilder: {info.splits['train'].num_examples}\")\n",
    "print(f\"Testbilder: {info.splits['test'].num_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa exempel\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, (image, label) in enumerate(train_ds.take(6)):\n",
    "    ax = plt.subplot(1, 6, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(class_names[label.numpy()])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F√∂rbered data - krympa och normalisera\n",
    "IMG_SIZE = 100\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = keras.ops.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = keras.ops.cast(image, 'float32') / 255.0  # Normalisera till 0-1 och kasta till float32\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(preprocess).batch(32).prefetch(1)\n",
    "test_ds = test_ds.map(preprocess).batch(32).prefetch(1)\n",
    "\n",
    "print(f\"Bildstorlek: {IMG_SIZE}x{IMG_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CNN-modell f√∂r Rock Paper Scissors\nmodel_rps = keras.Sequential([\n    layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n    \n    # F√∂rsta Conv-blocket: hitta enkla m√∂nster (kanter, linjer)\n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    # Andra Conv-blocket: hitta mer komplexa m√∂nster (fingrar, handflator)\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    # Tredje Conv-blocket: hitta gesterna\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    # Platta ut och klassificera\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(3, activation='softmax')  # rock, paper, scissors\n])\n\nmodel_rps.summary()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rps.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Tr√§nar CNN f√∂r Rock Paper Scissors...\")\n",
    "history_rps = model_rps.fit(train_ds, validation_data=test_ds, epochs=2, verbose=1)\n",
    "\n",
    "loss, acc = model_rps.evaluate(test_ds, verbose=0)\n",
    "print(f\"\\nTest Accuracy: {acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa prediktioner\n",
    "plt.figure(figsize=(15, 5))\n",
    "for images, labels in test_ds.take(1):\n",
    "    preds = model_rps.predict(images, verbose=0)\n",
    "    for i in range(min(8, len(images))):\n",
    "        ax = plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        pred_label = class_names[np.argmax(preds[i])]\n",
    "        true_label = class_names[labels[i].numpy()]\n",
    "        color = 'green' if pred_label == true_label else 'red'\n",
    "        plt.title(f\"Pred: {pred_label}\\nTrue: {true_label}\", color=color)\n",
    "        plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Testa med din webcam!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webcam i Colab - ta en bild och klassificera!\n",
    "from google.colab import output\n",
    "from IPython.display import display, Javascript\n",
    "from base64 import b64decode\n",
    "import cv2\n",
    "\n",
    "def take_photo():\n",
    "    \"\"\"Ta en bild med webcam i Colab.\"\"\"\n",
    "    js = Javascript('''\n",
    "        async function takePhoto() {\n",
    "            const video = document.createElement('video');\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "            video.srcObject = stream;\n",
    "            await video.play();\n",
    "            \n",
    "            // V√§nta lite s√• kameran hinner starta\n",
    "            await new Promise(resolve => setTimeout(resolve, 1500));\n",
    "            \n",
    "            const canvas = document.createElement('canvas');\n",
    "            canvas.width = video.videoWidth;\n",
    "            canvas.height = video.videoHeight;\n",
    "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "            \n",
    "            stream.getTracks().forEach(track => track.stop());\n",
    "            return canvas.toDataURL('image/jpeg', 0.8);\n",
    "        }\n",
    "        takePhoto();\n",
    "    ''')\n",
    "    display(js)\n",
    "    data = output.eval_js('takePhoto()')\n",
    "    \n",
    "    # Konvertera base64 till numpy array\n",
    "    binary = b64decode(data.split(',')[1])\n",
    "    img_array = np.frombuffer(binary, dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "print(\"G√∂r en gest (rock, paper eller scissors) och tryck Enter!\")\n",
    "input()\n",
    "photo = take_photo()\n",
    "\n",
    "# F√∂rbered bilden\n",
    "img_resized = cv2.resize(photo, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
    "img_input = np.expand_dims(img_resized, axis=0)\n",
    "\n",
    "# Klassificera\n",
    "pred = model_rps.predict(img_input, verbose=0)[0]\n",
    "predicted_class = class_names[np.argmax(pred)]\n",
    "confidence = np.max(pred) * 100\n",
    "\n",
    "# Visa resultat\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(photo)\n",
    "plt.title(f\"Modellen gissar: {predicted_class.upper()} ({confidence:.1f}% s√§ker)\", fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSannolikheter:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    bar = \"‚ñà\" * int(pred[i] * 30)\n",
    "    print(f\"  {name:8} {bar} {pred[i]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n### Uppgift 2: F√∂rst√• CNN-parametrar\n\nTitta p√• `model_rps.summary()` ovan och anv√§nd f√∂rklaringen av Conv2D fr√•n tidigare.\n\n**Fr√•gor att besvara (skriv dina svar i cellen nedan):**\n\n1. **F√∂rsta Conv2D-lagret** har input 100√ó100√ó3 (RGB) och 32 filter av storlek 3√ó3.\n   - Hur m√•nga vikter har *ett* filter? (T√§nk: en 3√ó3-matris per kanal)\n   - Hur m√•nga parametrar har lagret totalt? (Gl√∂m inte bias ‚Äî ett per filter!)\n   - St√§mmer det med vad `summary()` visar?\n\n2. **Output-storlek:** Varf√∂r visar summary att outputen fr√•n f√∂rsta Conv2D √§r 98√ó98 och inte 100√ó100?\n   - R√§kna: `output = input - filter + 1`\n\n3. **Andra Conv2D-lagret** tar emot 49√ó49√ó32 (efter MaxPooling).\n   - Hur m√•nga vikter har ett filter nu? (Ledtr√•d: nu √§r antalet kanaler 32, inte 3)\n   - Hur m√•nga parametrar totalt? St√§mmer det med summary?\n\n**Experimentera:** √Ñndra `(3, 3)` till `(5, 5)` i f√∂rsta Conv2D-lagret. \n- Vad h√§nder med antalet parametrar? \n- Vad h√§nder med output-storleken?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dina svar:\n#\n# 1. F√∂rsta Conv2D(32, (3,3)) med RGB-input:\n#    - Vikter per filter: 3 √ó 3 √ó ___ = ___\n#    - Parametrar per filter (med bias): ___ + 1 = ___\n#    - Totalt (32 filter): ___ √ó 32 = ___\n#\n# 2. Output-storlek: 100 - ___ + 1 = ___\n#\n# 3. Andra Conv2D(64, (3,3)) med 32 kanaler in:\n#    - Vikter per filter: 3 √ó 3 √ó ___ = ___\n#    - Parametrar per filter (med bias): ___ + 1 = ___\n#    - Totalt (64 filter): ___ √ó 64 = ___\n\n# Experimentera med (5,5) filter:\n# model_test = keras.Sequential([\n#     layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n#     layers.Conv2D(32, (5, 5), activation='relu'),\n#     layers.MaxPooling2D((2, 2)),\n#     layers.Conv2D(64, (3, 3), activation='relu'),\n#     layers.MaxPooling2D((2, 2)),\n#     layers.Conv2D(64, (3, 3), activation='relu'),\n#     layers.MaxPooling2D((2, 2)),\n#     layers.Flatten(),\n#     layers.Dense(64, activation='relu'),\n#     layers.Dense(3, activation='softmax')\n# ])\n# model_test.summary()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √ñvning 3: Kaffeb√∂nor - Sjukdomsdetektering ‚òï\n",
    "\n",
    "Klassificera om kaffeb√∂nor √§r friska eller sjuka.\n",
    "\n",
    "Dataset: [Beans (TensorFlow Datasets)](https://www.tensorflow.org/datasets/catalog/beans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladda Beans dataset\n",
    "(train_beans, val_beans, test_beans), info_beans = tfds.load(\n",
    "    'beans',\n",
    "    split=['train', 'validation', 'test'],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "bean_classes = ['angular_leaf_spot', 'bean_rust', 'healthy']\n",
    "print(f\"Klasser: {bean_classes}\")\n",
    "print(f\"Tr√§ningsbilder: {info_beans.splits['train'].num_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa exempel\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, (image, label) in enumerate(train_beans.take(6)):\n",
    "    ax = plt.subplot(1, 6, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(bean_classes[label.numpy()])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F√∂rbered data\n",
    "BEAN_SIZE = 128\n",
    "\n",
    "def preprocess_beans(image, label):\n",
    "   \n",
    "    image = keras.ops.image.resize(image, (BEAN_SIZE, BEAN_SIZE))\n",
    "    image = keras.ops.cast(image, 'float32') / 255.0  # Normalisera till 0-1 och kasta till float32\n",
    "    return image, label\n",
    "\n",
    "train_beans = train_beans.map(preprocess_beans).batch(32).prefetch(1)\n",
    "val_beans = val_beans.map(preprocess_beans).batch(32).prefetch(1)\n",
    "test_beans = test_beans.map(preprocess_beans).batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CNN f√∂r beans - samma struktur som RPS\nmodel_beans = keras.Sequential([\n    layers.Input(shape=(BEAN_SIZE, BEAN_SIZE, 3)),\n    \n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(3, activation='softmax')\n])\n\nmodel_beans.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nprint(\"Tr√§nar CNN f√∂r sjukdomsdetektering i kaffeb√∂nor...\")\nmodel_beans.fit(train_beans, validation_data=val_beans, epochs=2, verbose=1)\n\nloss, acc = model_beans.evaluate(test_beans, verbose=0)\nprint(f\"\\nTest Accuracy: {acc*100:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan forts√§tta tr√§na modellen d√§r vi slutade om vi inte √§r n√∂jd!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tr√§nar CNN f√∂r sjukdomsdetektering i kaffeb√∂nor...\")\n",
    "model_beans.fit(train_beans, validation_data=val_beans, epochs=2, verbose=1)\n",
    "\n",
    "loss, acc = model_beans.evaluate(test_beans, verbose=0)\n",
    "print(f\"\\nTest Accuracy: {acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN √§r kraftfullt!** Samma arkitektur fungerar f√∂r handgester och v√§xtsjukdomar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üß™ Snabbfr√•ga\n",
    "\n",
    "Rock Paper Scissors och Beans anv√§nder n√§stan identisk CNN-arkitektur, men bilderna √§r helt olika (handgester vs v√§xtblad).\n",
    "\n",
    "**Varf√∂r fungerar samma arkitektur f√∂r b√•da?**\n",
    "\n",
    "T√§nk p√• vad Conv2D-lagren faktiskt l√§r sig (kanter, former, texturer) och varf√∂r det √§r anv√§ndbart oavsett bildtyp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √ñvning 4: Sign Language MNIST ü§ü\n",
    "\n",
    "Klassificera amerikanskt teckenspr√•k (A-Z, utan J och Z som kr√§ver r√∂relse).\n",
    "\n",
    "Dataset: [Sign Language MNIST (Kaggle)](https://www.kaggle.com/datamunge/sign-language-mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout - F√∂rhindra overfitting\n",
    "\n",
    "Ett problem med neurala n√§tverk √§r **overfitting** - n√§tverket l√§r sig tr√§ningsdatan utantill ist√§llet f√∂r att generalisera.\n",
    "\n",
    "**Dropout** st√§nger av slumpm√§ssiga neuroner under tr√§ning:\n",
    "\n",
    "```\n",
    "Utan Dropout:              Med Dropout (50%):\n",
    "   ‚óã ‚óã ‚óã ‚óã                    ‚óã ‚úó ‚óã ‚úó\n",
    "   ‚îÇ‚ï≤‚îÇ‚ï±‚îÇ‚ï≤‚îÇ                    ‚îÇ   ‚îÇ  \n",
    "   ‚óã ‚óã ‚óã ‚óã       ‚Üí           ‚úó ‚óã ‚óã ‚úó\n",
    "   ‚îÇ‚ï≤‚îÇ‚ï±‚îÇ‚ï≤‚îÇ                      ‚îÇ‚ï±‚îÇ  \n",
    "   ‚óã ‚óã ‚óã ‚óã                    ‚óã ‚úó ‚óã ‚óã\n",
    "```\n",
    "\n",
    "Detta tvingar n√§tverket att inte f√∂rlita sig p√• enskilda neuroner, vilket ger b√§ttre generalisering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladda Sign Language MNIST\n",
    "# I Colab: ladda upp CSV-filer fr√•n Kaggle\n",
    "\n",
    "try:\n",
    "    # F√∂rs√∂k ladda lokalt\n",
    "    train_sl = pd.read_csv('sign_mnist_train.csv')\n",
    "    test_sl = pd.read_csv('sign_mnist_test.csv')\n",
    "except:\n",
    "    # I Colab: ladda fr√•n Kaggle (kr√§ver uppladdning)\n",
    "    print(\"Ladda ner fr√•n: https://www.kaggle.com/datamunge/sign-language-mnist\")\n",
    "    print(\"Ladda upp sign_mnist_train.csv och sign_mnist_test.csv\")\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    train_sl = pd.read_csv('sign_mnist_train.csv')\n",
    "    test_sl = pd.read_csv('sign_mnist_test.csv')\n",
    "\n",
    "# Separera labels och pixlar\n",
    "y_train_sl = train_sl['label'].values\n",
    "X_train_sl = train_sl.drop('label', axis=1).values.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "y_test_sl = test_sl['label'].values  \n",
    "X_test_sl = test_sl.drop('label', axis=1).values.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# 24 klasser (A-Z utan J och Z)\n",
    "letters = 'ABCDEFGHIKLMNOPQRSTUVWXY'  # Saknar J (9) och Z (25)\n",
    "\n",
    "print(f\"Tr√§ningsbilder: {len(X_train_sl)}\")\n",
    "print(f\"Testbilder: {len(X_test_sl)}\")\n",
    "print(f\"Klasser: {len(letters)} bokst√§ver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa exempel\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(X_train_sl[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(letters[y_train_sl[i]])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CNN med Dropout f√∂r Sign Language\nmodel_sign = keras.Sequential([\n    layers.Input(shape=(28, 28, 1)),\n    \n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Flatten(),\n    layers.Dropout(0.5),  # St√§ng av 50% av neuronerna under tr√§ning\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.3),  # St√§ng av 30% h√§r\n    layers.Dense(24, activation='softmax')  # 24 bokst√§ver\n])\n\nmodel_sign.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nprint(\"Tr√§nar Sign Language classifier...\")\nhistory_sign = model_sign.fit(\n    X_train_sl, y_train_sl,\n    epochs=15,\n    validation_split=0.1,\n    verbose=1\n)\n\nloss, acc = model_sign.evaluate(X_test_sl, y_test_sl, verbose=0)\nprint(f\"\\nTest Accuracy: {acc*100:.1f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa prediktioner\n",
    "plt.figure(figsize=(15, 6))\n",
    "indices = np.random.choice(len(X_test_sl), 12, replace=False)\n",
    "preds = model_sign.predict(X_test_sl[indices], verbose=0)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    ax = plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(X_test_sl[idx].reshape(28, 28), cmap='gray')\n",
    "    pred_letter = letters[np.argmax(preds[i])]\n",
    "    true_letter = letters[y_test_sl[idx]]\n",
    "    color = 'green' if pred_letter == true_letter else 'red'\n",
    "    plt.title(f\"{pred_letter} ({true_letter})\", color=color)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üß™ Uppgift 3: Dropout-effekten\n",
    "\n",
    "Modellen ovan anv√§nder `Dropout(0.5)` och `Dropout(0.3)`.\n",
    "\n",
    "**Din uppgift:** \n",
    "1. Tr√§na samma modell **utan** Dropout (ta bort eller kommentera bort Dropout-lagren)\n",
    "2. J√§mf√∂r tr√§nings-accuracy vs validerings-accuracy\n",
    "3. Vilken modell har st√∂rst gap mellan tr√§ning och validering? Vad betyder det?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Modell UTAN dropout\nmodel_no_dropout = keras.Sequential([\n    layers.Input(shape=(28, 28, 1)),\n    \n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    # Ingen Dropout h√§r!\n    layers.Dense(128, activation='relu'),\n    # Ingen Dropout h√§r heller!\n    layers.Dense(24, activation='softmax')\n])\n\nmodel_no_dropout.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nprint(\"Tr√§nar UTAN dropout...\")\nhistory_no_drop = model_no_dropout.fit(X_train_sl, y_train_sl, epochs=15, validation_split=0.1, verbose=1)\n\n# J√§mf√∂r: titta p√• sista epoch - hur stor √§r skillnaden mellan accuracy och val_accuracy?\n# Med dropout: _____ vs _____\n# Utan dropout: _____ vs _____"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Del 3: F√∂rtr√§nade modeller (Transfer Learning)\n",
    "\n",
    "Att tr√§na ett CNN fr√•n scratch kr√§ver:\n",
    "- Miljontals bilder\n",
    "- Dagar av GPU-tid\n",
    "\n",
    "**Transfer Learning:** Anv√§nd ett n√§tverk som n√•gon annan redan tr√§nat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GlobalAveragePooling2D\n",
    "\n",
    "N√§r vi anv√§nder f√∂rtr√§nade modeller beh√∂ver vi koppla ihop deras output med v√•rt klassificeringslager.\n",
    "\n",
    "F√∂rtr√§nade modeller ger output som en 3D-tensor (h√∂jd √ó bredd √ó kanaler). `GlobalAveragePooling2D` tar genomsnittet f√∂r varje kanal:\n",
    "\n",
    "```\n",
    "Input: (7, 7, 1280)    ‚Üí    Output: (1280,)\n",
    "\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ 1 2 3 4 ‚îÇ\n",
    "‚îÇ 5 6 7 8 ‚îÇ  ‚Üí genomsnitt = 4.5\n",
    "‚îÇ 1 2 3 4 ‚îÇ    (f√∂r varje kanal)\n",
    "‚îÇ 5 6 7 8 ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "Resultatet √§r en 1D-vektor som kan g√• in i Dense-lager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √ñvning 5: Transfer Learning - Katter vs Hundar\n",
    "\n",
    "Vi anv√§nder MobileNetV2 (tr√§nad p√• 14 miljoner bilder) och byter bara ut sista lagret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladda katter vs hundar (20% f√∂r snabbhet)\n",
    "(train_cats, val_cats), info_cats = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:20%]', 'train[20%:25%]'],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "print(f\"Tr√§ningsbilder: {len(train_cats)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa bilder\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, (image, label) in enumerate(train_cats.take(8)):\n",
    "    ax = plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Katt\" if label == 0 else \"Hund\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F√∂rbered data\n",
    "IMG_SIZE_TL = 160\n",
    "\n",
    "def preprocess_tl(image, label):\n",
    "    image = keras.ops.image.resize(image, (IMG_SIZE_TL, IMG_SIZE_TL))\n",
    "    image = keras.ops.cast(image, 'float32') # Cast to float32\n",
    "    image = keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "train_cats = train_cats.map(preprocess_tl).batch(32).prefetch(1)\n",
    "val_cats = val_cats.map(preprocess_tl).batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladda MobileNetV2 (utan topplagret)\n",
    "base_model = keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_SIZE_TL, IMG_SIZE_TL, 3),\n",
    "    include_top=False,  # Ta bort klassificeringslagret\n",
    "    weights='imagenet'  # Anv√§nd f√∂rtr√§nade vikter\n",
    ")\n",
    "\n",
    "# Frys alla lager - vi √§ndrar INTE de f√∂rtr√§nade vikterna\n",
    "base_model.trainable = False\n",
    "\n",
    "print(f\"MobileNet: {len(base_model.layers)} lager\")\n",
    "print(f\"Output shape: {base_model.output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bygg v√•r modell\n",
    "model_transfer = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),  # (5, 5, 1280) ‚Üí (1280,)\n",
    "    layers.Dense(1, activation='sigmoid')  # Katt (0) eller Hund (1)\n",
    "])\n",
    "\n",
    "model_transfer.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Tr√§nar (bara v√•rt nya lager)...\")\n",
    "model_transfer.fit(train_cats, validation_data=val_cats, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model_transfer.evaluate(val_cats, verbose=0)\n",
    "print(f\"\\nAccuracy: {acc*100:.1f}%!\")\n",
    "print(\"Med bara 2 epoker och 20% av datan!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üß™ Uppgift 4: Fine-tuning\n",
    "\n",
    "Vi fr√∂s alla lager i MobileNetV2 (`base_model.trainable = False`). \n",
    "\n",
    "**Din uppgift:** Vad h√§nder om vi \"tinar\" de sista lagren och tr√§nar vidare?\n",
    "\n",
    "1. K√∂r koden nedan som tinar de 20 sista lagren\n",
    "2. Tr√§na vidare med en **l√§gre** learning rate (viktigt!)\n",
    "3. Blir accuracy b√§ttre eller s√§mre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning: tina de sista 20 lagren\n",
    "base_model.trainable = True\n",
    "\n",
    "# Frys alla UTOM de sista 20\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"Tr√§ningsbara lager: {sum(1 for l in base_model.layers if l.trainable)}\")\n",
    "\n",
    "# Kompilera med L√ÑGRE learning rate (viktigt vid fine-tuning!)\n",
    "model_transfer.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # 10x l√§gre\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Tr√§na vidare\n",
    "print(\"Fine-tuning...\")\n",
    "model_transfer.fit(train_cats, validation_data=val_cats, epochs=2)\n",
    "\n",
    "loss, acc = model_transfer.evaluate(val_cats, verbose=0)\n",
    "print(f\"\\nAccuracy efter fine-tuning: {acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Del 4: Sekvenser - LSTM\n",
    "\n",
    "Dense och CNN hanterar data med fast storlek. Men vad om input √§r en **sekvens** av varierande l√§ngd? (Text, ljud, tidsserier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## LSTM (Long Short-Term Memory)\n\n### Problemet: Dense har inget minne\n\nMed ett Dense-lager kan vi mata in en hel sekvens p√• en g√•ng, men n√§tverket har ingen aning om **ordningen**. Orden \"katten √•t musen\" och \"musen √•t katten\" ser likadana ut ‚Äî bara en p√•se med ord. Vi beh√∂ver ett lager som l√§ser ett element i taget och **kommer ih√•g** vad det l√§st.\n\n### Grundid√©n: ett rullande minne\n\nLSTM l√§ser sekvensen **ett steg i taget** (ett tecken, ett ord, en datapunkt). Vid varje steg har den tv√• saker:\n\n- **G√∂mt tillst√•nd (h)** ‚Äî en vektor som sammanfattar \"vad har jag sett hittills?\" (storlek = antal units)\n- **Cellminne (C)** ‚Äî en intern vektor med l√•ngtidsminne\n\n```\n                h‚ÇÄ=0         h‚ÇÅ          h‚ÇÇ          h‚ÇÉ\n                 ‚Üì            ‚Üì            ‚Üì            ‚Üì\nTecken:     ‚îÄ‚Üí [LSTM] ‚îÄ‚îÄ‚Üí [LSTM] ‚îÄ‚îÄ‚Üí [LSTM] ‚îÄ‚îÄ‚Üí [LSTM] ‚îÄ‚îÄ‚Üí h‚ÇÑ (output)\n                 ‚Üë            ‚Üë            ‚Üë            ‚Üë\n                \"t\"          \"h\"          \"e\"          \" \"\n\n                C‚ÇÄ=0 ‚îÄ‚îÄ‚Üí    C‚ÇÅ   ‚îÄ‚îÄ‚Üí    C‚ÇÇ   ‚îÄ‚îÄ‚Üí    C‚ÇÉ   ‚îÄ‚îÄ‚Üí  C‚ÇÑ\n                        (cellminne fl√∂dar fram√•t, uppdateras vid varje steg)\n```\n\nI b√∂rjan √§r h och C nollvektorer. Vid varje steg uppdateras de baserat p√• nuvarande input.\n\n### De tre grindarna (gates)\n\nLSTM har tre \"grindar\" som styr informationsfl√∂det. Varje grind √§r ett lager med sigmoid-aktivering (output 0‚Äì1), d√§r 0 = \"st√§ng\" och 1 = \"√∂ppna\":\n\n**1. Gl√∂mgrinden (forget gate)** ‚Äî *\"Vad i minnet √§r inte l√§ngre relevant?\"*\n\nTittar p√• f√∂rra tillst√•ndet (h) och nuvarande input (x) och best√§mmer vad som ska **raderas** fr√•n cellminnet.\n\n**2. Inmatningsgrinden (input gate)** ‚Äî *\"Vad nytt ska sparas i minnet?\"*\n\nBest√§mmer vilken ny information som ska **l√§ggas till** i cellminnet.\n\n**3. Utmatningsgrinden (output gate)** ‚Äî *\"Vad fr√•n minnet √§r relevant just nu?\"*\n\nBest√§mmer vad fr√•n cellminnet som ska bli det nya g√∂mda tillst√•ndet (h), som skickas vidare till n√§sta steg.\n\n### Konkret exempel: l√§sa \"the cat sat on the ___\"\n\n```\nSteg 1: input = \"t\"    Gl√∂mgrinden: inget att gl√∂mma (minnet √§r tomt)\n  h‚ÇÄ = [0,0,0,...]     Inmatningsgrinden: spara att vi sett ett \"t\"\n                        Utmatningsgrinden: uppdatera h ‚Üí h‚ÇÅ\n\nSteg 2: input = \"h\"    Gl√∂mgrinden: beh√•ll \"t\" ‚Äî kan vara viktigt\n  h‚ÇÅ                    Inmatningsgrinden: spara \"th\"-kombination\n                        Utmatningsgrinden: ‚Üí h‚ÇÇ\n\n  ...\n\nSteg 9: input = \"t\"    Gl√∂mgrinden: vi har l√§st \"the cat s\" ‚Äî gl√∂m detaljer om \"the\"\n                        Inmatningsgrinden: nytt \"t\" kan b√∂rja nytt ord\n                        Utmatningsgrinden: ‚Üí h‚Çâ sammanfattar \"the cat sat...\"\n\n  ... (forts√§tter till slutet)\n\nSteg 40: output = h‚ÇÑ‚ÇÄ  Denna vektor sammanfattar hela sekvensen!\n                        Dense-lagret anv√§nder h‚ÇÑ‚ÇÄ f√∂r att gissa n√§sta tecken.\n```\n\n### Vad h√§nder inuti en grind? (f√∂renklat)\n\nVarje grind √§r i princip ett litet Dense-lager med sigmoid:\n\n```\nforget_gate = sigmoid( W_f √ó [h_f√∂rra, x_nu] + bias_f )\n                       ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n                       vikter som LSTM l√§r sig\n\nExempel (f√∂renklat med 3 units):\n\n  h_f√∂rra = [0.5, -0.2, 0.8]     (f√∂rra g√∂mda tillst√•ndet)\n  x_nu    = [0.1, 0.9, -0.3]     (embedding av nuvarande tecken)\n\n  [h, x]  = [0.5, -0.2, 0.8, 0.1, 0.9, -0.3]    (sl√• ihop: 6 v√§rden)\n\n  W_f √ó [h, x] + bias ‚Üí [1.2, -0.5, 0.3]         (viktad summa)\n\n  sigmoid ‚Üí [0.77, 0.38, 0.57]   ‚Üê beslut per minnesposition\n              ‚îÇ      ‚îÇ      ‚îÇ\n              ‚îÇ      ‚îÇ      ‚îî‚îÄ \"beh√•ll 57% av position 3\"\n              ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \"gl√∂m 62% av position 2\"\n              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ \"beh√•ll 77% av position 1\"\n```\n\nCellminnet multipliceras elementvis med grind-vektorn:\n```\n  C_nytt = C_gammalt √ó forget_gate + ny_info √ó input_gate\n```\n\nInput-grinden och output-grinden fungerar likadant ‚Äî egna vikter, samma princip.\n\n### Parametrar i LSTM\n\nVarje grind har vikter f√∂r **b√•de input (x) och f√∂rra tillst√•ndet (h)**, plus bias:\n\n```\nEn grind:  input_dim √ó units  +  units √ó units  +  units\n           (vikter f√∂r x)        (vikter f√∂r h)     (bias)\n```\n\nLSTM har **4 upps√§ttningar vikter** (forget, input, cell-kandidat, output):\n\n```\nI v√•r Shakespeare-modell: Embedding(64) ‚Üí LSTM(128)\n\n  input_dim = 64,  units = 128\n\n  Per grind:  64 √ó 128  +  128 √ó 128  +  128  =  24 704\n  Totalt:     4 √ó 24 704 = 98 816 parametrar\n```\n\nJ√§mf√∂r med `model_text.summary()` ‚Äî st√§mmer det?\n\n### Sammanfattning: Dense vs LSTM\n\n```\nDense:   Alla inputs ‚Üí alla outputs (ingen ordning, inget minne)\n         Bra f√∂r: tabelldata, klassificering efter Flatten\n\nLSTM:    L√§ser ett element i taget, b√§r med sig minne\n         Bra f√∂r: text, tidsserier, musik ‚Äî allt d√§r ordningen spelar roll\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Embedding - Ord till vektorer\n\n### Problemet: n√§tverk f√∂rst√•r inte text\n\nNeurala n√§tverk jobbar med tal, inte ord. Vi beh√∂ver ett s√§tt att omvandla varje ord till en vektor av tal som n√§tverket kan r√§kna med.\n\n### En naiv l√∂sning: one-hot encoding\n\nVi *skulle* kunna one-hot-encoda varje ord, precis som vi gjort med kategorier tidigare:\n\n```\n\"cat\" ‚Üí [1, 0, 0, 0, ..., 0]    (10 000 element ‚Äî ett per unikt ord)\n\"dog\" ‚Üí [0, 1, 0, 0, ..., 0]\n\"the\" ‚Üí [0, 0, 1, 0, ..., 0]\n```\n\nProblemet: vektorerna s√§ger ingenting om **relationer**. \"cat\" och \"dog\" √§r lika olika som \"cat\" och \"the\". Dessutom blir vektorerna enorma om vi har tusentals ord i vokabul√§ret.\n\n### Embedding: en inl√§rningsbar uppslagstabell\n\n`Embedding` l√∂ser b√•da problemen. Den √§r egentligen bara en **viktmatris** ‚Äî en tabell d√§r varje rad √§r en kort, t√§t vektor som representerar ett ord:\n\n```\nEmbedding(vocab_size=10000, embedding_dim=128)\n\n                           128 tal per ord\n                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n  Index 0 (\"the\"):  ‚îÇ  0.12  -0.45   0.78  0.33 ... ‚îÇ  ‚Üê rad 0\n  Index 1 (\"cat\"):  ‚îÇ -0.33   0.91   0.02  0.15 ... ‚îÇ  ‚Üê rad 1\n  Index 2 (\"dog\"):  ‚îÇ -0.28   0.85   0.08  0.19 ... ‚îÇ  ‚Üê rad 2  (n√§ra \"cat\"!)\n    ...              ‚îÇ  ...    ...    ...   ...       ‚îÇ\n  Index 9999:        ‚îÇ  0.08   0.34  -0.51  0.72 ... ‚îÇ  ‚Üê rad 9999\n                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n  Matrisstorlek: 10 000 rader √ó 128 kolumner = 1 280 000 parametrar\n```\n\n### Hur det fungerar steg f√∂r steg\n\n```\nInput-mening:    \"the cat sat\"\n\nSteg 1: Omvandla ord till index (via en ordlista)\n  \"the\" ‚Üí 0,  \"cat\" ‚Üí 1,  \"sat\" ‚Üí 45\n\nSteg 2: Sl√• upp varje index i tabellen\n  Index 0  ‚Üí [ 0.12, -0.45,  0.78, ...,  0.33]    (rad 0)\n  Index 1  ‚Üí [-0.33,  0.91,  0.02, ...,  0.15]    (rad 1)\n  Index 45 ‚Üí [ 0.56, -0.12, -0.67, ...,  0.44]    (rad 45)\n\nOutput: en matris med 3 rader √ó 128 kolumner (en vektor per ord)\n```\n\nDet √§r allt! Embedding √§r bara: **index ‚Üí sl√• upp rad i tabell ‚Üí vektor**.\n\n### Vikterna l√§rs under tr√§ning\n\nDet smarta: vektorerna i tabellen √§r **vikter som n√§tverket l√§r sig** under tr√§ning, precis som vikterna i Dense-lager. N√§tverket l√§r sig att placera ord som anv√§nds i liknande sammanhang **n√§ra varandra** i vektorrummet:\n\n```\nF√∂re tr√§ning (slumpm√§ssiga):       Efter tr√§ning (meningsfulla):\n\n  \"cat\" ‚Üí [0.52, -0.31, ...]        \"cat\" ‚Üí [ 0.8,  0.3, ...]\n  \"dog\" ‚Üí [0.11,  0.87, ...]        \"dog\" ‚Üí [ 0.7,  0.4, ...]  ‚Üê n√§ra \"cat\" (b√•da djur)\n  \"the\" ‚Üí [-0.44, 0.02, ...]        \"the\" ‚Üí [-0.5, -0.6, ...]  ‚Üê l√•ngt bort (annat slags ord)\n  \"car\" ‚Üí [0.73, -0.65, ...]        \"car\" ‚Üí [-0.2,  0.1, ...]  ‚Üê helt annan riktning\n```\n\nBer√∂mda word embeddings som Word2Vec och GloVe har visat att man till och med kan r√§kna med vektorerna:\n```\n  king - man + woman ‚âà queen\n```\n\n### I v√•r Shakespeare-modell: tecken ist√§llet f√∂r ord\n\nSamma princip fungerar p√• **vilken niv√• som helst**. I Shakespeare-modellen anv√§nder vi Embedding p√• **teckenniv√•** ‚Äî varje bokstav och skiljetecken f√•r en egen vektor:\n\n```\nEmbedding(vocab_size=39, embedding_dim=64)\n\n  39 unika tecken (a-z, mellanslag, punkt, etc.) √ó 64-dimensionell vektor\n\n  \"t\" ‚Üí index 33 ‚Üí [-0.21,  0.55, -0.08, ...,  0.33]\n  \"h\" ‚Üí index 21 ‚Üí [ 0.44, -0.12,  0.91, ..., -0.67]\n  \"e\" ‚Üí index 18 ‚Üí [ 0.78,  0.03, -0.45, ...,  0.12]\n\n  Parametrar: 39 √ó 64 = 2 496\n```\n\nVi anv√§nder tecken ist√§llet f√∂r ord h√§r eftersom Shakespeare-texten har ett begr√§nsat alfabet, och vi vill att modellen ska kunna generera text bokstav f√∂r bokstav.\n\n### Parametrar\n\nEmbedding har **inga bias** ‚Äî bara vikttabellen:\n\n```\nParametrar = vocab_size √ó embedding_dim\n```\n\nJ√§mf√∂r med `model_text.summary()` ‚Äî st√§mmer 2 496?\n\n### Embedding vs One-hot\n\n| | One-hot | Embedding |\n|---|---|---|\n| Vektorstorlek | vocab_size (kan bli enormt) | valfritt, t.ex. 64 eller 128 |\n| Relationer | inga ‚Äî alla ord lika olika | l√§r sig likheter |\n| Parametrar | 0 (fast kodning) | vocab_size √ó dim |\n| Anv√§nds av | enklare modeller | LSTM, Transformers, etc. |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √ñvning 6: Textgenerering - Shakespeare-bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladda Shakespeare-text\n",
    "path = keras.utils.get_file('shakespeare.txt',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(path).read().lower()[:100000]  # F√∂rsta 100k tecken\n",
    "\n",
    "print(f\"Textl√§ngd: {len(text):,} tecken\")\n",
    "print(f\"\\nExempel:\\n{text[:300]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F√∂rbered data\n",
    "chars = sorted(set(text))\n",
    "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
    "idx_to_char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "print(f\"Unika tecken: {len(chars)}\")\n",
    "\n",
    "# Skapa sekvenser: givet 40 tecken, vad √§r n√§sta?\n",
    "SEQ_LEN = 40\n",
    "sequences, targets = [], []\n",
    "\n",
    "for i in range(0, len(text) - SEQ_LEN, 3):\n",
    "    sequences.append([char_to_idx[c] for c in text[i:i+SEQ_LEN]])\n",
    "    targets.append(char_to_idx[text[i+SEQ_LEN]])\n",
    "\n",
    "X_text = np.array(sequences)\n",
    "y_text = keras.utils.to_categorical(targets, len(chars))\n",
    "\n",
    "print(f\"Tr√§ningssekvenser: {len(X_text):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# LSTM-modell\nmodel_text = keras.Sequential([\n    layers.Input(shape=(SEQ_LEN,)),\n    layers.Embedding(len(chars), 64),  # Tecken ‚Üí vektor\n    layers.LSTM(128),  # Sekvens ‚Üí en vektor (med minne)\n    layers.Dense(len(chars), activation='softmax')  # ‚Üí n√§sta tecken\n])\n\nmodel_text.compile(optimizer='adam', loss='categorical_crossentropy')\nmodel_text.summary()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tr√§nar Shakespeare-bot...\")\n",
    "model_text.fit(X_text, y_text, batch_size=128, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(seed, length=300, temperature=0.7):\n",
    "    \"\"\"Generera text fr√•n en startfras.\"\"\"\n",
    "    result = seed.lower()\n",
    "    \n",
    "    for _ in range(length):\n",
    "        x = np.array([[char_to_idx.get(c, 0) for c in result[-SEQ_LEN:]]])\n",
    "        preds = model_text.predict(x, verbose=0)[0]\n",
    "        \n",
    "        # Temperature: l√§gre = s√§krare, h√∂gre = kreativare\n",
    "        preds = np.log(preds + 1e-8) / temperature\n",
    "        preds = np.exp(preds) / np.sum(np.exp(preds))\n",
    "        \n",
    "        next_char = idx_to_char[np.random.choice(len(chars), p=preds)]\n",
    "        result += next_char\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Shakespeare-bot skriver:\")\n",
    "print(\"=\"*50)\n",
    "print(generate(\"to be or not to be\", length=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prova egen startfras!\n",
    "print(generate(\"love is \", length=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üß™ Uppgift 5: Temperature-parametern\n",
    "\n",
    "I `generate()`-funktionen finns en parameter `temperature`. \n",
    "\n",
    "- **L√•g temperature (0.2):** Modellen v√§ljer n√§stan alltid det mest troliga tecknet ‚Üí mer \"s√§ker\" men tr√•kig text\n",
    "- **H√∂g temperature (1.5):** Modellen v√§ljer mer slumpm√§ssigt ‚Üí kreativare men kan bli nonsens\n",
    "\n",
    "**Din uppgift:** Testa olika temperatures och beskriv skillnaden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"the king\"\n",
    "\n",
    "print(\"=== Temperature 0.2 (s√§ker/tr√•kig) ===\")\n",
    "print(generate(seed, length=150, temperature=0.2))\n",
    "\n",
    "print(\"\\n=== Temperature 0.7 (balanserad) ===\")\n",
    "print(generate(seed, length=150, temperature=0.7))\n",
    "\n",
    "print(\"\\n=== Temperature 1.5 (kreativ/kaotisk) ===\")\n",
    "print(generate(seed, length=150, temperature=1.5))\n",
    "\n",
    "# Vilken temperature tycker du ger b√§st resultat? Varf√∂r?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Del 5: Neural Style Transfer\n",
    "\n",
    "Kombinera inneh√•llet fr√•n en bild med stilen fr√•n en annan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "# F√∂rtr√§nad style transfer-modell\n",
    "style_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
    "print(\"Style transfer-modell laddad!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, max_dim=512):\n",
    "    img = np.array(keras.utils.load_img(path))  # Ladda direkt fr√•n s√∂kv√§g\n",
    "    scale = max_dim / max(img.shape[:2])\n",
    "    img = keras.ops.image.resize(img, (int(img.shape[0]*scale), int(img.shape[1]*scale)))\n",
    "    return (keras.ops.cast(img, 'float32') / 255.0)[np.newaxis, ...]\n",
    "\n",
    "content = load_img('apple.jpg')\n",
    "style = load_img('vangogh.jpg')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(content[0]); axes[0].set_title('Inneh√•ll'); axes[0].axis('off')\n",
    "axes[1].imshow(style[0]); axes[1].set_title('Stil (Starry Night)'); axes[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magi!\n",
    "result = style_model(content, style)[0]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(result[0])\n",
    "plt.title('Resultat!')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prova med din egen bild!\n",
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "print(\"Ladda upp en bild att stilisera:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    img_np = np.array(Image.open(io.BytesIO(uploaded[filename])).resize((512, 512))) / 255.0\n",
    "    img = keras.ops.convert_to_tensor(img_np[np.newaxis, ...], dtype='float32')\n",
    "\n",
    "    result = style_model(img, style)[0]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    axes[0].imshow(img[0]); axes[0].set_title('Original'); axes[0].axis('off')\n",
    "    axes[1].imshow(result[0]); axes[1].set_title('Stiliserad'); axes[1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Sammanfattning\n\n## Nya lagertyper\n\n| Lager | Vad det g√∂r | Anv√§nds f√∂r |\n|-------|-------------|-------------|\n| **Input** | Definierar formen p√• indata | Alltid f√∂rst i modellen |\n| **Dense** | Alla inputs kopplas till alla outputs | Klassificering, regression |\n| **Conv2D** | Litet filter som glider √∂ver bilden | Bilder - hittar lokala m√∂nster |\n| **MaxPooling2D** | Krymper bilden (tar max i varje ruta) | Bilder - minskar storlek |\n| **Flatten** | 2D ‚Üí 1D | Koppla ihop CNN med Dense |\n| **GlobalAveragePooling2D** | Genomsnitt per kanal | Koppla f√∂rtr√§nade modeller |\n| **Embedding** | Ord/tecken ‚Üí vektor | Text - representation |\n| **LSTM** | Sekvens med minne | Text, ljud, tidsserier |\n| **Dropout** | St√§nger av slumpm√§ssiga neuroner | F√∂rhindra overfitting |\n\n## Vad du l√§rt dig\n\n1. **Keras-syntax** f√∂r samma problem du redan kunde (bilklassificering)\n2. **ReLU och Adam** - moderna alternativ till sigmoid och SGD\n3. **CNN** - specialiserat f√∂r bilder (Rock Paper Scissors, Kaffeb√∂nor, Sign Language)\n4. **Dropout** - f√∂rhindra overfitting\n5. **Transfer Learning** - anv√§nd f√∂rtr√§nade modeller (Katter vs Hundar)\n6. **LSTM** - hantera sekvenser (Shakespeare-bot)\n7. **Style Transfer** - kreativa till√§mpningar\n\nAllt bygger p√• samma grund: vikter, bias, aktivering, backpropagation!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}